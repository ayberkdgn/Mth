{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e4f08c",
   "metadata": {},
   "source": [
    "## ğŸ§© 1. NLP Nedir?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a52a5c",
   "metadata": {},
   "source": [
    "**DoÄŸal Dil Ä°ÅŸleme (Natural Language Processing â€“ NLP)**, bilgisayarlarÄ±n insan diliyle etkileÅŸime geÃ§mesini saÄŸlayan bir yapay zekÃ¢ alanÄ±dÄ±r.\n",
    "\n",
    "ğŸ”¹ **KÃ¶keni:** Bilgisayar bilimi, yapay zekÃ¢ ve dilbilimin kesiÅŸiminde yer alÄ±r.        \n",
    "ğŸ”¹ **AmacÄ±:** Ä°nsan dilini anlamak, yorumlamak ve Ã¼retmek.\n",
    "\n",
    "### ğŸ§  GerÃ§ek Hayat UygulamalarÄ±:\n",
    "- Sesli asistanlar (Siri, ChatGPT, Alexa)\n",
    "- Google Translate\n",
    "- Duygu Analizi\n",
    "- Spam Filtreleme\n",
    "- Bilgi Ã‡Ä±karma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79349651",
   "metadata": {},
   "source": [
    "## ğŸš€ 2. Uygulamalar ve Temel Teknolojiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b7487",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Uygulamalar:\n",
    "- Makine Ã‡evirisi (Google Translate)\n",
    "- Bilgi Getirimi (Information Retrieval)\n",
    "- Soru Cevaplama (QA)\n",
    "- Diyalog Sistemleri (Chatbotlar)\n",
    "- Metin Ã–zeti, Duygu Analizi, Bilgi Ã‡Ä±karma\n",
    "\n",
    "### ğŸ”¹ Temel Teknolojiler:\n",
    "- Dil Modellemesi\n",
    "- SÃ¶zcÃ¼k TÃ¼rÃ¼ Etiketleme (POS Tagging)\n",
    "- Ad Ã–beÄŸi TanÄ±ma (NER)\n",
    "- Anlamsal Rol Etiketleme (SRL)\n",
    "- Kelime AnlamÄ± BelirsizliÄŸinin Giderilmesi (WSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba579d",
   "metadata": {},
   "source": [
    "## ğŸ§© 3. Pythonâ€™da PopÃ¼ler NLP KÃ¼tÃ¼phaneleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c486bb",
   "metadata": {},
   "source": [
    "- **NLTK** â€“ EÄŸitim ve araÅŸtÄ±rma iÃ§in kullanÄ±lÄ±r.\n",
    "- **spaCy** â€“ HÄ±zlÄ±, Ã¼retim odaklÄ± bir NLP kÃ¼tÃ¼phanesi.\n",
    "- **gensim** â€“ Word2Vec, Doc2Vec, TF-IDF gibi modelleri iÃ§erir.\n",
    "- **HuggingFace Transformers** â€“ BERT, GPT, RoBERTa gibi modern modelleri destekler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acb859",
   "metadata": {},
   "source": [
    "## ğŸ§¹ 4. Metin Ã–n Ä°ÅŸleme (Text Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76895d3d",
   "metadata": {},
   "source": [
    "**AmaÃ§:** Metinleri modellemeye uygun hale getirme sÃ¼recidir.\n",
    "\n",
    "**Neden YapÄ±yoruz:** GerÃ§ek dÃ¼nyadan gelen veriler genellikle gÃ¼rÃ¼ltÃ¼lÃ¼dÃ¼r. Bu yÃ¼zden modelin daha iyi anlamasÄ± iÃ§in temizleme gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb13e34",
   "metadata": {},
   "source": [
    "### 1ï¸âƒ£ KÃ¼Ã§Ã¼k Harfe Ã‡evirme (Lowercasing)\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "Metindeki tÃ¼m harfleri kÃ¼Ã§Ã¼k hale getirerek kelimelerin biÃ§imsel farklarÄ±nÄ± ortadan kaldÄ±rmak.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- Makine Ã¶ÄŸrenmesi modelleri â€œAppleâ€, â€œappleâ€ ve â€œAPPLEâ€ kelimelerini farklÄ± varlÄ±klar olarak gÃ¶rÃ¼r.\n",
    "- Bu da veri setinde gereksiz kelime Ã§eÅŸitliliÄŸi (noise) oluÅŸturur ve modelin Ã¶ÄŸrenmesini zorlaÅŸtÄ±rÄ±r.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**    \n",
    "- Kelime vektÃ¶rlerinin daÄŸÄ±lmasÄ±nÄ± engeller, veri birliÄŸini saÄŸlar.\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fd8c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing is fun!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Natural Language Processing Is FUN!\"\n",
    "text.lower()\n",
    "# 'natural language processing is fun!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a871fed",
   "metadata": {},
   "source": [
    "### 2ï¸âƒ£ Noktalama ve Ã–zel Karakter Temizleme\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "Metindeki anlam taÅŸÄ±mayan sembol, noktalama ve Ã¶zel karakterleri kaldÄ±rmak.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- Noktalama iÅŸaretleri genellikle anlamsal bilgi taÅŸÄ±maz, Ã¶zellikle klasik NLP modellerinde (BoW, TF-IDF).\n",
    "\n",
    "- â€œHello!!! NLP@2025 is great :)â€ gibi ifadeler gereksiz karakterlerle doludur.\n",
    "\n",
    "- Bu karakterler modelin kelime uzayÄ±nÄ± (vocabulary) ÅŸiÅŸirir ve gÃ¼rÃ¼ltÃ¼ oluÅŸturur.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**   \n",
    "- Daha temiz, sade ve verimli bir kelime temsili elde edilir.\n",
    "\n",
    "**ğŸ§® Kod:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"Hello!!! NLP@2025 is great :)\"\n",
    "re.sub(r'[^\\w\\s]', '', text)\n",
    "# 'Hello NLP2025 is great'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b878d",
   "metadata": {},
   "source": [
    "### 3ï¸âƒ£ Stop-Word KaldÄ±rma\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "â€œtheâ€, â€œisâ€, â€œandâ€, â€œaâ€ gibi anlamÄ± az, sÄ±k kullanÄ±lan kelimeleri kaldÄ±rmak.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "Bu kelimeler:\n",
    "\n",
    "- CÃ¼mlenin duygusal veya anlamsal iÃ§eriÄŸine katkÄ± yapmaz.\n",
    "\n",
    "- Modelin Ã¶nemli kelimelere **(â€œThe movie was not badâ€ â†’ ['movie', 'not', 'bad'])** odaklanmasÄ±nÄ± engeller.\n",
    "\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**   \n",
    "- Model sadece anlamlÄ± kelimeleri Ã¶ÄŸrenir, performans artar, gÃ¼rÃ¼ltÃ¼ azalÄ±r.\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(\"This is an example of stopword removal.\")\n",
    "filtered = [w for w in tokens if w.lower() not in stop_words]\n",
    "# ['example', 'stopword', 'removal', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e3e5b",
   "metadata": {},
   "source": [
    "### 4ï¸âƒ£ URL ve HTML Etiketlerini KaldÄ±rma\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "Web sayfalarÄ±ndan Ã§ekilen verilerdeki baÄŸlantÄ± (URL) ve HTML etiketlerini temizlemek.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- Web scraping verilerinde (div), (a), (br) gibi etiketler bulunur.\n",
    "\n",
    "- â€œhttps://huggingface.co/blogâ€ gibi linkler metnin anlamÄ±na katkÄ± yapmaz.\n",
    "\n",
    "- Bu semboller metin analizinde hatalÄ± tokenlar oluÅŸturur.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**   \n",
    "- Model sadece doÄŸal dil Ã¼zerinde Ã§alÄ±ÅŸÄ±r, anlamsÄ±z veri elemanlarÄ±ndan arÄ±ndÄ±rÄ±lÄ±r.\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"Visit https://huggingface.co/blog for tutorials <br> NLP rocks!\"\n",
    "text = re.sub(r'http\\\\S+', '', text)\n",
    "text = re.sub(r'<.*?>', '', text)\n",
    "# 'Visit  for tutorials  NLP rocks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7239b39",
   "metadata": {},
   "source": [
    "### 5ï¸âƒ£ KÃ¶k Bulma (Stemming)\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "Kelimeleri kÃ¶klerine indirgemek â€” biÃ§imsel varyasyonlarÄ± birleÅŸtirmek.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- â€œprogrammingâ€, â€œprogrammerâ€, â€œprogramsâ€ gibi kelimeler aynÄ± kavramÄ± temsil eder.\n",
    "- Fakat model bunlarÄ± farklÄ± kelimeler olarak gÃ¶rÃ¼r.\n",
    "- Stemming sayesinde hepsi â€œprogramâ€ haline gelir.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**   \n",
    "Bu sayede:\n",
    "\n",
    "- Kelimelerin Ã§eÅŸitliliÄŸi azalÄ±r (dimensionality reduction)\n",
    "\n",
    "- Veri boyutu kÃ¼Ã§Ã¼lÃ¼r\n",
    "\n",
    "- Benzer anlamlÄ± kelimeler aynÄ± kategoride toplanÄ±r\n",
    "\n",
    "âš ï¸ Ancak stemming sadece yazÄ± biÃ§imine bakar, anlamÄ± korumaz.\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c75635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"programming\", \"programmer\", \"programs\"]\n",
    "[stemmer.stem(w) for w in words]\n",
    "# ['program', 'programmer', 'program']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069606e",
   "metadata": {},
   "source": [
    "**ğŸ“‰ ZayÄ±f yÃ¶n:**       \n",
    "â€œbetterâ€ â†’ â€œbetâ€ gibi yanlÄ±ÅŸ kesimler olabilir.     \n",
    "Bu yÃ¼zden genellikle lemmatization tercih edilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfd0b3",
   "metadata": {},
   "source": [
    "### 6ï¸âƒ£ Lemmatization\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**\n",
    "\n",
    "Kelimeleri sÃ¶zlÃ¼kteki gerÃ§ek kÃ¶k biÃ§imine (lemma) indirgemek.\n",
    "Yani sadece harf bazlÄ± deÄŸil, anlamsal ve gramatik dÃ¶nÃ¼ÅŸÃ¼m yapÄ±lÄ±r.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**\n",
    "\n",
    "Lemmatization:\n",
    "\n",
    "- Kelimenin sÃ¶zlÃ¼k anlamÄ±nÄ± dikkate alÄ±r.\n",
    "\n",
    "- Dilbilgisel tÃ¼rÃ¼nÃ¼ (isim, fiil, sÄ±fat) analiz eder.\n",
    "\n",
    "- â€œamâ€, â€œareâ€, â€œisâ€ â†’ â€œbeâ€\n",
    "\n",
    "- â€œrunningâ€, â€œranâ€ â†’ â€œrunâ€\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**     \n",
    "- Daha doÄŸru, anlam koruyan kelime temsilleri elde edilir.  \n",
    "- Derin Ã¶ÄŸrenme ve dil modellemede performansÄ± artÄ±rÄ±r.\n",
    "\n",
    "    | Ã–zellik  | Stemming   | Lemmatization  |\n",
    "    | -------- | ---------- | -------------- |\n",
    "    | Temel    | Harf kesme | SÃ¶zlÃ¼k tabanlÄ± |\n",
    "    | Anlam    | Korunmaz   | Korunur        |\n",
    "    | HÄ±z      | HÄ±zlÄ±      | Daha yavaÅŸ     |\n",
    "    | DoÄŸruluk | DÃ¼ÅŸÃ¼k      | YÃ¼ksek         |\n",
    "\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8417f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"running\", pos=\"v\")\n",
    "# 'run'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a3891",
   "metadata": {},
   "source": [
    "### 7ï¸âƒ£ Tokenization\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**        \n",
    "Metni anlamlÄ± kÃ¼Ã§Ã¼k birimlere (kelimelere veya cÃ¼mlelere) ayÄ±rmak.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- NLP modelleri kelime dÃ¼zeyinde Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "- Tokenization yapÄ±lmadan kelime sayÄ±mÄ±, TF-IDF veya embedding iÅŸlemi yapÄ±lamaz.\n",
    "\n",
    "- AyrÄ±ca dil modellemesi (Language Modeling) iÃ§in de Ã¶n koÅŸuldur.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**    \n",
    "- Modelin Ã¶ÄŸrenme birimleri belirlenir.   \n",
    "- Bir metin artÄ±k sayÄ±sal hale getirilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58202a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"NLP is awesome!\")\n",
    "# ['NLP', 'is', 'awesome', '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9072c91",
   "metadata": {},
   "source": [
    "### 8ï¸âƒ£ Normalization\n",
    "\n",
    "**ğŸ¯ AmaÃ§:**    \n",
    "Kelimeleri biÃ§imsel olarak tek bir standarda dÃ¶nÃ¼ÅŸtÃ¼rmek.\n",
    "\n",
    "**ğŸ’¡ Neden YapÄ±yoruz:**     \n",
    "- FarklÄ± yazÄ±m biÃ§imleri ve aksanlar veri karmaÅŸasÄ± yaratÄ±r.\n",
    "- â€œcafÃ©â€, â€œCafeâ€, â€œCAFEâ€ aynÄ± kelimedir ama model iÃ§in farklÄ±dÄ±r.\n",
    "- â€œIâ€™mâ€ â†’ â€œI amâ€, â€œğŸ˜Šâ€ â†’ â€œhappyâ€ gibi dÃ¶nÃ¼ÅŸÃ¼mler, semantik analizde tutarlÄ±lÄ±ÄŸÄ± artÄ±rÄ±r.\n",
    "\n",
    "**ğŸ“ˆ SonuÃ§:**       \n",
    "- GÃ¼rÃ¼ltÃ¼ azaltÄ±lÄ±r\n",
    "- Model genelleme kabiliyeti artar\n",
    "- Kelime vektÃ¶rleri daha kararlÄ± hale gelir\n",
    "\n",
    "**ğŸ§® Kod:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76426a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "text = \"CafÃ© costs â‚¬5\"\n",
    "text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "# 'Cafe costs 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56284a8c",
   "metadata": {},
   "source": [
    "### ğŸ“Š Genel Ã–zet\n",
    "Metin Ã¶n iÅŸleme, modelin anlamlÄ± bilgileri daha kolay Ã¶ÄŸrenmesini saÄŸlar. Bu adÄ±mlar, veriyi temizler, gÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r ve model performansÄ±nÄ± artÄ±rÄ±r.\n",
    "\n",
    "| AdÄ±m | AmaÃ§ |\n",
    "|------|------|\n",
    "| Lowercasing | Harf farklarÄ±nÄ± kaldÄ±rÄ±r |\n",
    "| Noktalama Temizleme | GÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r |\n",
    "| Stopword KaldÄ±rma | AnlamsÄ±z kelimeleri Ã§Ä±karÄ±r |\n",
    "| URL & HTML Temizleme | Web gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ temizler |\n",
    "| Stemming/Lemmatization | KÃ¶k forma indirger |\n",
    "| Tokenization | Metni kelimelere ayÄ±rÄ±r |\n",
    "| Normalization | YazÄ±m biÃ§imlerini standartlaÅŸtÄ±rÄ±r |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93143518",
   "metadata": {},
   "source": [
    "## ğŸ§© 5. METÄ°N TEMSÄ°LÄ° (TEXT REPRESENTATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9343df0",
   "metadata": {},
   "source": [
    "### 1ï¸âƒ£ Temel AmaÃ§\n",
    "\n",
    "Bilgisayarlar metni doÄŸrudan anlayamaz; Ã§Ã¼nkÃ¼ metin nÃ¼merik olmayan (sembolik) bir formattadÄ±r.     \n",
    "Bu yÃ¼zden, kelimeleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek gerekir.   \n",
    "AmaÃ§:   \n",
    "- Metnin anlamÄ±nÄ± ve baÄŸlamÄ±nÄ± mÃ¼mkÃ¼n olduÄŸunca koruyarak\n",
    "- sayÄ±sal formda (vektÃ¶r) ifade etmek.\n",
    "\n",
    "Bu temsiller makine Ã¶ÄŸrenmesi modellerinin girdisi olur.    \n",
    "Ã–rneÄŸin, â€œBugÃ¼n hava gÃ¼zelâ€ cÃ¼mlesi â†’ [0.1, 0.8, 0.5, â€¦] gibi bir vektÃ¶r olarak modele verilir.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b5e83",
   "metadata": {},
   "source": [
    "\n",
    "### 2ï¸âƒ£ GiriÅŸ: Neden Temsile Ä°htiyaÃ§ Var?\n",
    "\n",
    "Bilgisayarlar kelimeleri anlayamaz; onlar yalnÄ±zca **sayÄ±larla** Ã§alÄ±ÅŸÄ±r.  \n",
    "Bu yÃ¼zden her kelimeyi veya cÃ¼mleyi **vektÃ¶rlere (sayÄ± dizilerine)** dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekir.\n",
    "\n",
    "Ama nasÄ±l bir dÃ¶nÃ¼ÅŸÃ¼m?  \n",
    "Ä°ÅŸte bunun iÃ§in geliÅŸtirilen Ã¼Ã§ ana dÃ¶nem var:\n",
    "\n",
    "1. **Klasik DÃ¶nem:**\n",
    "   - _Bag-of-Words, TF-IDF_\n",
    "   - Sadece kelime sÄ±klÄ±ÄŸÄ±na bakar.\n",
    "2. **Anlamsal DÃ¶nem:**\n",
    "   - _Word2Vec, GloVe, FastText_\n",
    "   - Kelimelerin anlam benzerliÄŸini yakalar.\n",
    "3. **BaÄŸlamsal DÃ¶nem:**\n",
    "   - _BERT, GPT, ChatGPT_\n",
    "   - Kelimelerin **cÃ¼mledeki baÄŸlamÄ±na gÃ¶re** temsilini Ã¶ÄŸrenir.\n",
    "\n",
    "Bu Ã¼Ã§ dÃ¶nem, NLPâ€™nin evrim zinciri gibidir ğŸ§¬\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57a1b9",
   "metadata": {},
   "source": [
    "\n",
    "### 3ï¸âƒ£ Bag-of-Words (BoW) â€” â€œKelime TorbasÄ±â€ Modeli\n",
    "\n",
    "**ğŸ“˜ Fikir:**   \n",
    "Her dokÃ¼man, iÃ§indeki kelimelerin **varlÄ±k ve sÄ±klÄ±k bilgisiyle** temsil edilir.  \n",
    "Yani bir belgeyi sadece â€œhangi kelimeler var ve kaÃ§ kez geÃ§miÅŸâ€ Ã¼zerinden temsil edersin.   \n",
    "Kelime sÄ±rasÄ± veya anlam Ã¶nemli deÄŸildir.   \n",
    " \n",
    ">Belge 1: the cat sat   \n",
    ">Belge 2: the cat sat on the mat\n",
    "\n",
    "\n",
    "**ğŸ§® AdÄ±mlar:** \n",
    "1. TÃ¼m belgelerdeki **benzersiz kelimeleri (vocabulary)** bul.  \n",
    "2. Her belge iÃ§in, her kelimenin kaÃ§ kez geÃ§tiÄŸini say.  \n",
    "3. BunlarÄ± bir tabloya koy: **Document-Term Matrix (DTM)**\n",
    "\n",
    "    | Kelime | D1 | D2 |\n",
    "    |:--|:--|:--|\n",
    "    | the | 1 | 2 |\n",
    "    | cat | 1 | 1 |\n",
    "    | sat | 1 | 1 |\n",
    "    | on | 0 | 1 |\n",
    "    | mat | 0 | 1 |\n",
    "\n",
    "> D1 â†’ [1,1,1,0,0], D2 â†’ [2,1,1,1,1]\n",
    "\n",
    "**âœ… Avantaj:** \n",
    "- Basit, hÄ±zlÄ±, anlaÅŸÄ±lÄ±r.  \n",
    "- Klasik ML algoritmalarÄ±yla iyi Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "**âŒ Dezavantaj:**  \n",
    "- Kelime sÄ±rasÄ± yok.  \n",
    "- Anlam veya baÄŸlam yok.   \n",
    "\n",
    "> â€œdog bites manâ€ = â€œman bites dogâ€  \n",
    "> â€” Yani baÄŸlam kayboldu.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f07e95",
   "metadata": {},
   "source": [
    "\n",
    "### 4ï¸âƒ£ TF-IDF â€” â€œKelimelerin Ã–nemini Ã–lÃ§mekâ€\n",
    "\n",
    "**Motivasyon:**     \n",
    "BoW sadece kelime sayÄ±yor ama â€œÃ¶nemli kelime mi, yoksa sÄ±k kullanÄ±lan bir baÄŸlaÃ§ mÄ±?â€ ayÄ±rt edemiyor.   \n",
    "Mesela â€œtheâ€ Ã§ok geÃ§er ama bilgi taÅŸÄ±maz.   \n",
    "Fakat kelime sÄ±rasÄ±, anlam ve baÄŸlam hal Ã¶enmli deÄŸildir.\n",
    "\n",
    "**MantÄ±k:**\n",
    "\n",
    "- **TF (Term Frequency):** Kelime bir belgede ne kadar sÄ±k geÃ§iyor?   \n",
    "  ğŸ‘‰ SÄ±klÄ±ÄŸÄ± yÃ¼ksekse, o belge iÃ§in Ã¶nemli olabilir.\n",
    "\n",
    "- **IDF (Inverse Document Frequency):** Kelime tÃ¼m belgelerde ne kadar nadir?   \n",
    "  ğŸ‘‰ Nadir kelimeler genelde daha anlamlÄ±dÄ±r (Ã¶rneÄŸin â€œquantumâ€ â†’ daha bilgi verici).\n",
    "\n",
    "  \n",
    "**ğŸ’¡ BOW Ve TF-IDF FarkÄ±:**\n",
    "\n",
    "- **BoW:** kelime sÄ±klÄ±ÄŸÄ±na gÃ¶re temsil\n",
    "\n",
    "- **TF-IDF:** kelimenin sÄ±klÄ±ÄŸÄ± yanÄ±nda ayÄ±rt ediciliÄŸine (nadirliÄŸe) gÃ¶re temsil\n",
    "\n",
    "- Bu yÃ¼zden TF-IDF, arama motorlarÄ±nda (Google gibi) belge sÄ±ralamada kullanÄ±lÄ±r.\n",
    "\n",
    "**âœ… Avantaj:**\n",
    "- Kelimelerin Ã¶nem derecesini ayÄ±rt eder.  \n",
    "- Arama motorlarÄ±nda (Google, Bing) hÃ¢lÃ¢ temel yÃ¶ntemdir.  \n",
    "\n",
    "**âŒ Dezavantaj:**\n",
    "- Kelime sÄ±rasÄ± ve baÄŸlam hÃ¢lÃ¢ yok.  \n",
    "- â€œgoodâ€ ile â€œnot goodâ€ farkÄ±nÄ± anlamaz.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc85a8e",
   "metadata": {},
   "source": [
    "\n",
    "### 5ï¸âƒ£ Word Embeddings â€” â€œAnlamÄ± SayÄ±ya DÃ¶kmekâ€\n",
    "\n",
    "**Motivasyon:**\n",
    "BoW ve TF-IDF â€œsayÄ±sal ama anlamsÄ±zâ€ â€” Ã§Ã¼nkÃ¼ kelime sÄ±rasÄ± ve anlam iliÅŸkileri yok.   \n",
    "Oysa â€œkingâ€ ile â€œqueenâ€ benzer anlamlÄ±dÄ±r, bunu BoW fark edemez.    \n",
    "\n",
    "**MantÄ±k:**\n",
    "Her kelimeyi bir vektÃ¶r (Ã¶rneÄŸin 100 boyutlu sayÄ± listesi) ile temsil ederiz.   \n",
    "Bu vektÃ¶rler Ã¶ÄŸrenilir â€” yani model, bÃ¼yÃ¼k metinleri tarayarak ÅŸu prensibi Ã¶ÄŸrenir:   \n",
    "\n",
    "> â€œBir kelimenin anlamÄ±, Ã§evresindeki kelimelerden anlaÅŸÄ±lÄ±r.â€    \n",
    "\n",
    "\n",
    "**ğŸ”¹ Word2Vec (Google, 2013)**\n",
    "Ä°ki modelle Ã§alÄ±ÅŸÄ±r:\n",
    "- **CBOW (Continuous Bag of Words):** BaÄŸlamdan hedef kelimeyi tahmin eder.  \n",
    "  > BaÄŸlam: {â€œtheâ€, â€œsatâ€, â€œonâ€} â†’ Tahmin: â€œcatâ€  \n",
    "- **Skip-Gram:** Hedef kelimeden baÄŸlamÄ± tahmin eder.  \n",
    "  > Hedef: â€œcatâ€ â†’ Tahmin: {â€œtheâ€, â€œsatâ€, â€œonâ€}\n",
    "\n",
    "**ğŸ”¹ GloVe (Global Vectors)**\n",
    "- Kelime Ã§iftlerinin istatistiksel birlikte bulunma sÄ±klÄ±klarÄ±na bakar.  \n",
    "- Daha â€œmatematikselâ€ bir embedding Ã¼retir.\n",
    "\n",
    "**ğŸ”¹ FastText (Facebook)**\n",
    "- Kelimeleri **alt parÃ§alara (subword)** bÃ¶ler â†’ yeni kelimeleri de anlayabilir.  \n",
    "  > â€œrunâ€, â€œrunnerâ€, â€œrunningâ€ aynÄ± kÃ¶kten gelir.\n",
    "\n",
    "\n",
    "\n",
    "**âœ… Avantaj:**\n",
    "- Anlam benzerliÄŸini yakalar.  \n",
    "- Makine Ã¶ÄŸrenmesi modelleriyle Ã§ok iyi Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "**âŒ Dezavantaj:**\n",
    "- **BaÄŸlam duyarsÄ±zdÄ±r.**  \n",
    "  â€œAppleâ€ hem meyve hem ÅŸirket olsa da hep aynÄ± vektÃ¶rdÃ¼r.  \n",
    "- Uzun cÃ¼mle anlamlarÄ±nÄ± yakalayamaz.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1c2ac",
   "metadata": {},
   "source": [
    "\n",
    "### 6ï¸âƒ£ BaÄŸlamsal Temsiller â€” â€œHer Kelime CÃ¼mledeki RolÃ¼ne GÃ¶reâ€\n",
    "\n",
    "Bu noktada devrim geldi:\n",
    "> **Transformers** (Google, 2017) ve **BERT / GPT** ailesi.\n",
    "\n",
    "**ğŸ”¹ Temel Fikir:**\n",
    "Her kelimenin anlamÄ± **bulunduÄŸu cÃ¼mleye gÃ¶re deÄŸiÅŸir.**  \n",
    "Yani embedding artÄ±k **dinamik**.\n",
    "\n",
    "> â€œHe went to the **bank** to withdraw money.â€  \n",
    "> â€œHe sat by the **bank** of the river.â€  \n",
    "> Ä°ki â€œbankâ€ kelimesinin vektÃ¶rÃ¼ tamamen farklÄ±dÄ±r.\n",
    "\n",
    "\n",
    "**âš™ï¸ Transformer YapÄ±sÄ± (KÄ±saca)**\n",
    "Transformer, â€œ**self-attention**â€ mekanizmasÄ±yla Ã§alÄ±ÅŸÄ±r:  \n",
    "Her kelime, cÃ¼mledeki **diÄŸer tÃ¼m kelimelere dikkat (attention)** eder.\n",
    "\n",
    "Ã–rneÄŸin:  \n",
    "> â€œThe animal didnâ€™t cross the street because it was too tired.â€  \n",
    "> Buradaki â€œitâ€ kelimesi hangi kelimeye baÄŸlÄ±? â€œanimalâ€ mÄ± â€œstreetâ€ mi?  \n",
    "> Self-attention bunu **Ã¶ÄŸrenir**.\n",
    "\n",
    "**ğŸ’¡ SonuÃ§:**\n",
    "Her kelime iÃ§in **baÄŸlamsal embedding** Ã¼retilir.  \n",
    "Bu embedding, hem kelimenin kendisini hem de tÃ¼m cÃ¼mlenin anlamÄ±nÄ± taÅŸÄ±r.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77f977",
   "metadata": {},
   "source": [
    "\n",
    "### 8ï¸âƒ£ KÄ±saca\n",
    "\n",
    "ğŸ§  **Metin temsili**, NLPâ€™nin temelidir.  \n",
    "Bilgisayara dil Ã¶ÄŸretmek, kelimeleri sayÄ±larla anlatmak demektir.\n",
    "\n",
    "Evrim ÅŸu ÅŸekilde olmuÅŸtur:\n",
    "\n",
    "> **BoW â†’ TF-IDF â†’ Word2Vec â†’ BERT â†’ GPT â†’ ChatGPT**\n",
    "\n",
    "BugÃ¼n, **ChatGPT gibi modeller**, bu sÃ¼recin zirvesinde:\n",
    "- Her kelimenin anlamÄ±nÄ± baÄŸlama gÃ¶re temsil ediyor,\n",
    "- CÃ¼mleler arasÄ± iliÅŸkileri Ã¶ÄŸreniyor,\n",
    "- Sadece metin deÄŸil, gÃ¶rsel ve ses gibi modaliteleri de anlayabiliyor (GPT-4).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Ã–zellik | BoW | TF-IDF | Word2Vec | BERT / GPT |\n",
    "|:--|:--|:--|:--|:--|\n",
    "| Boyut | Ã‡ok yÃ¼ksek | YÃ¼ksek | Orta | Ã‡ok yÃ¼ksek |\n",
    "| Anlam | Yok | Yok | Var | âœ” Dinamik |\n",
    "| BaÄŸlam | âŒ | âŒ | âŒ | âœ” |\n",
    "| KullanÄ±m AlanÄ± | Basit ML | Arama motoru | Orta seviye NLP | ChatGPT, Copilot, vs. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f7da1",
   "metadata": {},
   "source": [
    "## ğŸ§® 6. SÄ±nÄ±flandÄ±rma (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ab27a",
   "metadata": {},
   "source": [
    "\n",
    "SÄ±nÄ±flandÄ±rma, **bir girdiyi belirli bir kategoriye atama** problemidir.  \n",
    "Bu NLPâ€™de metinleri etiketlemek iÃ§in Ã§ok yaygÄ±ndÄ±r.\n",
    "\n",
    "### ğŸ“˜ Temel TanÄ±m\n",
    "Bir model, belirli bir metin veya Ã¶zellik setine karÅŸÄ±lÄ±k gelen **etiketi (label)** tahmin eder.  \n",
    "Yani giriÅŸ â†’ â€œBu film mÃ¼kemmeldi.â€  \n",
    "Ã‡Ä±kÄ±ÅŸ â†’ â€œPozitifâ€.\n",
    "\n",
    "### ğŸ¯ KullanÄ±m AlanlarÄ±\n",
    "- **Spam tespiti:** E-postalarÄ± *spam / ham* olarak sÄ±nÄ±flandÄ±rmak.  \n",
    "- **Duygu analizi:** YorumlarÄ± *pozitif / negatif / nÃ¶tr* olarak etiketlemek.  \n",
    "- **Konu sÄ±nÄ±flandÄ±rmasÄ±:** Haberleri *spor / ekonomi / politika* olarak ayÄ±rmak.  \n",
    "- **KullanÄ±cÄ± davranÄ±ÅŸÄ±:** Bir mÃ¼ÅŸterinin *churn (abonelikten Ã§Ä±kma)* olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmek.  \n",
    "\n",
    "### ğŸ§  Tipik YaklaÅŸÄ±m\n",
    "1. **Veri Toplama:** ÃœrÃ¼n yorumlarÄ±, tweetler vb.  \n",
    "2. **Ã–n Ä°ÅŸleme:** Temizleme, stop-word kaldÄ±rma, lemmatization.  \n",
    "3. **Ã–zellik Ã‡Ä±karÄ±mÄ±:** Metin â†’ sayÄ±sal vektÃ¶r (TF-IDF, Word2Vec, BERT embedding).  \n",
    "4. **Modelleme:**  \n",
    "   - Basit: Naive Bayes, Logistic Regression, SVM  \n",
    "   - Derin: RNN, LSTM, Transformer  \n",
    "5. **DeÄŸerlendirme:** Accuracy, Precision, Recall, F1-score  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf02cd",
   "metadata": {},
   "source": [
    "## â¤ï¸ 7. Duygu Analizi (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da51186",
   "metadata": {},
   "source": [
    "Slaytta bu konuya Ã¶zel birkaÃ§ sayfa ayrÄ±lmÄ±ÅŸ.  \n",
    "**AmaÃ§:** Bir metindeki duygusal tonun (*pozitif, negatif, nÃ¶tr*) tespit edilmesi.\n",
    "\n",
    "### ğŸ’¬ KullanÄ±m AlanlarÄ±\n",
    "- **Sosyal medya:** Marka takibi, mÃ¼ÅŸteri memnuniyeti.  \n",
    "- **E-ticaret:** ÃœrÃ¼n yorumlarÄ±nÄ±n analiz edilmesi.  \n",
    "- **Finans:** Piyasa haberlerinden duygu yÃ¶nÃ¼ Ã§Ä±karÄ±mÄ±.  \n",
    "- **Film / oyun yorumlarÄ±:** Genel beÄŸeni Ã¶lÃ§Ã¼mÃ¼.  \n",
    "\n",
    "### âš™ï¸ Tipik Ä°ÅŸlem HattÄ± (Pipeline)\n",
    "1. **Veri Toplama:** Twitter API, Yelp, Amazon Reviews.  \n",
    "2. **Metin Temizleme:** KÃ¼Ã§Ã¼k harfe Ã§evirme, URL/simge kaldÄ±rma.  \n",
    "3. **Ã–zellik Ã‡Ä±karÄ±mÄ±:**  \n",
    "   - TF-IDF â†’ kelime sÄ±klÄ±k temsili  \n",
    "   - Word2Vec / GloVe â†’ anlam temsili  \n",
    "4. **Model EÄŸitimi:**  \n",
    "   - Klasik ML â†’ Naive Bayes, SVM  \n",
    "   - Derin Ã–ÄŸrenme â†’ LSTM, GRU, BERT  \n",
    "5. **Tahmin & GÃ¶rselleÅŸtirme:** Metin â†’ Duygu etiketi (% pozitif / negatif oranÄ±)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa104d0",
   "metadata": {},
   "source": [
    "## ğŸ§© 8. Dil Modelleri ve N-gramlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cb8da",
   "metadata": {},
   "source": [
    "PDFâ€™de bu bÃ¶lÃ¼m â€œLanguage Modelsâ€ ve â€œN-gram Language Modelsâ€ baÅŸlÄ±ÄŸÄ± altÄ±nda iki aÅŸamada anlatÄ±lmÄ±ÅŸ.\n",
    "\n",
    "### ğŸ“– Dil Modeli (Language Model)\n",
    "Dil modeli dediÄŸimiz ÅŸey, bir cÃ¼mledeki bir sonraki kelimenin ne olabileceÄŸini olasÄ±lÄ±kla tahmin eden bir sistemdir.        \n",
    "Bilgisayara â€œBu kelimeden sonra genelde ne gelir?â€ Ã¶ÄŸretmek gibi dÃ¼ÅŸÃ¼nebilirsin.        \n",
    "\n",
    "**ğŸ”¹ Ã–rnek:**\n",
    "\n",
    "> â€œBugÃ¼n hava Ã§ok â€¦â€        \n",
    "\n",
    "Burada â€œgÃ¼zelâ€ ya da â€œsoÄŸukâ€ gibi kelimeler gelme olasÄ±lÄ±ÄŸÄ± yÃ¼ksektir.      \n",
    "Model, daha Ã¶nce gÃ¶rdÃ¼ÄŸÃ¼ cÃ¼mlelerden Ã¶ÄŸrenerek bu olasÄ±lÄ±klarÄ± hesaplar.        \n",
    "\n",
    "### ğŸ”¡ N-gram Modeli\n",
    "Bir dil modelinin en basit tÃ¼rÃ¼:    \n",
    "N-gram, bir cÃ¼mledeki kelime gruplarÄ± demektir.     \n",
    "- Unigram: 1 kelime â†’ â€œbugÃ¼nâ€   \n",
    "- Bigram: 2 kelime â†’ â€œbugÃ¼n havaâ€   \n",
    "- Trigram: 3 kelime â†’ â€œbugÃ¼n hava gÃ¼zelâ€    \n",
    "\n",
    "Model, Ã¶nceki 1 veya 2 kelimeye bakarak sonraki kelimeyi tahmin eder.   \n",
    "Ne kadar Ã§ok kelimeye bakarsa, o kadar doÄŸru tahmin eder â€” ama daha fazla veriye ihtiyaÃ§ duyar.     \n",
    "\n",
    "**âš–ï¸ Avantaj / Dezavantaj**     \n",
    "- âœ… Basit, hÄ±zlÄ±, kolay anlaÅŸÄ±lÄ±r.     \n",
    "- âŒ Uzun cÃ¼mlelerde baÄŸlamÄ± unutur (â€œbugÃ¼n havaâ€ â†’ tamam ama â€œbugÃ¼n hava gÃ¼zel olmasÄ±na raÄŸmenâ€¦â€ gibi uzun yapÄ±lar zor).       \n",
    "- âŒ Yeni kelimeleri tanÄ±yamaz (Ã¶rneÄŸin daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi bir kelime gelirse).        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b589b",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ 9. SÃ¶zcÃ¼k TÃ¼rÃ¼ Etiketleme (POS Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacab0bc",
   "metadata": {},
   "source": [
    "**Part-of-Speech (POS) Tagging**       \n",
    "Her kelimenin dilbilgisel gÃ¶revini bulmak anlamÄ±na gelir.   \n",
    "Yani o kelime isim mi, fiil mi, sÄ±fat mÄ±?   \n",
    "\n",
    "### ğŸ” Ã–rnek\n",
    "> â€œThe quick brown fox jumps over the lazy dogâ€  \n",
    "> â†’ the (DT), quick (JJ), brown (JJ), fox (NN), jumps (VBZ), â€¦\n",
    "\n",
    "### ğŸ’¡ FaydalarÄ±\n",
    "- CÃ¼mleyi gramer aÃ§Ä±sÄ±ndan analiz etmeyi saÄŸlar.  \n",
    "- **Ã‡eviri**, **Sentiment Analysis** ve **NER** gÃ¶revlerinde yardÄ±mcÄ± olur.  \n",
    "- Bilgi Ã§Ä±karÄ±mÄ± ve arama kalitesini artÄ±rÄ±r.  \n",
    "\n",
    "### âš ï¸ Zorluklar\n",
    "- **Ã‡ok anlamlÄ±lÄ±k (ambiguity):** â€œbookâ€ hem fiil hem isim olabilir.  \n",
    "- **Yeni kelimeler (OOV):** Modelin gÃ¶rmediÄŸi kelimeler.  \n",
    "- **Alan baÄŸÄ±mlÄ±lÄ±ÄŸÄ±:** TÄ±p, hukuk gibi Ã¶zel alanlarda baÅŸarÄ±m dÃ¼ÅŸebilir.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ee0ef",
   "metadata": {},
   "source": [
    "## ğŸ§â€â™‚ï¸ 10. Ad Ã–beÄŸi TanÄ±ma (Named Entity Recognition - NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5d36d",
   "metadata": {},
   "source": [
    "**NER**, metindeki Ã¶nemli varlÄ±klarÄ± (kiÅŸi, yer, tarih, kurum) tespit eder.\n",
    "\n",
    "### ğŸ“„ Ã–rnek\n",
    "> â€œApple Inc. is planning to open a new office in San Francisco in March 2025.â€  \n",
    "> â†’ Apple Inc. (Organization)  \n",
    "> â†’ San Francisco (Location)  \n",
    "> â†’ March 2025 (Date)\n",
    "\n",
    "### âš™ï¸ Uygulamalar\n",
    "- **Chatbotlar:** KullanÄ±cÄ±dan alÄ±nan bilgileri anlamlandÄ±rmak.  \n",
    "- **Haber analizi:** KiÅŸi, Ã¼lke, kurum bazlÄ± gruplama.  \n",
    "- **CV analizi:** Ä°sim, beceri, eÄŸitim bilgisi Ã§Ä±karÄ±mÄ±.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37309e3a",
   "metadata": {},
   "source": [
    "## ğŸ” 11. Bilgi Getirimi (Information Retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef71ed",
   "metadata": {},
   "source": [
    "Bu, arama motorlarÄ±nÄ±n temelidir.       \n",
    "KÄ±saca: BÃ¼yÃ¼k bir metin yÄ±ÄŸÄ±nÄ± iÃ§inde kullanÄ±cÄ±ya en alakalÄ± bilgiyi bulma iÅŸlemidir.       \n",
    "\n",
    "**ğŸ”¹ Ã–rnek:**\n",
    "\n",
    "Googleâ€™a yazÄ±yorsun:\n",
    "\n",
    "> â€œNLP applicationsâ€\n",
    "\n",
    "Google ÅŸunlarÄ± yapÄ±yor:\n",
    "\n",
    "- **Belge Koleksiyonu:** Milyonlarca sayfa.\n",
    "\n",
    "- **Sorgu (query):** Senin yazdÄ±ÄŸÄ±n kelimeler.\n",
    "\n",
    "- **Ä°ndeksleme:** Her sayfayÄ± hÄ±zlÄ± bulunacak ÅŸekilde saklÄ±yor (ters indeks).\n",
    "\n",
    "- **SÄ±ralama:** Hangi sayfa en alakalÄ±? (Ã¶rneÄŸin TF-IDF skorlarÄ±yla).\n",
    "\n",
    "- **SonuÃ§:** En uygun sayfalarÄ± gÃ¶steriyor.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
