{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f8a40c",
   "metadata": {},
   "source": [
    "# ğŸš€ BÃœYÃœK DÄ°L MODELLERÄ° â€” EN BASÄ°T VE MANTIKLI ANLATIM\n",
    "\n",
    "Bu dersi tek bir soruyla aÃ§Ä±klayalÄ±m:\n",
    "\n",
    "> **â€œBir dil modelini nasÄ±l insan gibi konuÅŸturur, nasÄ±l gÃ¶revlere uygun hale getirir, nasÄ±l gÃ¼venli kÄ±lar ve nasÄ±l akÄ±l yÃ¼rÃ¼tmesini saÄŸlarÄ±z?â€**\n",
    "\n",
    "Cevap 4 aÅŸamada gelir:  \n",
    "**Pretraining â†’ Finetuning â†’ Alignment â†’ Reasoning**\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Pretraining â€” Modelin dili Ã¶ÄŸrenmesi (Temel EÄŸitim)\n",
    "\n",
    "Pretraining aÅŸamasÄ±, modelin internetteki, kitaplardaki ve devasa veri kaynaklarÄ±ndaki metinlerle dili Ã¶ÄŸrenmesi sÃ¼recidir.\n",
    "\n",
    "Bu aÅŸama ÅŸunun gibidir:\n",
    "\n",
    "> **Modeli trilyonlarca kelimeyle baÅŸ baÅŸa bÄ±rakÄ±yoruz ve â€œBu kelimeden sonra ne gelir?â€ tahmini yapmasÄ±nÄ± Ã¶ÄŸretiyoruz.**\n",
    "\n",
    "### Model bu aÅŸamada ÅŸunlarÄ± Ã¶ÄŸrenir:\n",
    "- Dilin kurallarÄ±  \n",
    "- Kelimeler arasÄ± iliÅŸkiler  \n",
    "- DÃ¼nya bilgisi  \n",
    "- Uzun baÄŸlam iliÅŸkileri  \n",
    "\n",
    "Bu aÅŸama *etiketsiz veridir* ve hiÃ§bir gÃ¶rev Ã¶ÄŸretmez.\n",
    "\n",
    "### âœ” Neden gerekli?\n",
    "Bir Ã§ocuk Ã¶nce dili Ã¶ÄŸrenmeden yazÄ± yazamaz veya problem Ã§Ã¶zemez.  \n",
    "Model de Ã¶nce dili Ã¶ÄŸrenmek zorundadÄ±r.\n",
    "\n",
    "### ğŸ” Neden Ã§ok pahalÄ±?\n",
    "\n",
    "- DeepSeek: 14.8 trilyon token\n",
    "- 57 gÃ¼n eÄŸitim\n",
    "- Milyonlarca dolar maliyet\n",
    "\n",
    "Ã‡Ã¼nkÃ¼ model dev gibi (milyarlarca parametre) ve veri sonsuz.\n",
    "\n",
    "### âœ” Pretraining sonunda model:\n",
    "- Dili Ã§ok iyi anlar  \n",
    "- DÃ¼nya bilgisine sahiptir  \n",
    "- Ama hÃ¢lÃ¢ hamdÄ±r, gÃ¶rev yapamaz, gÃ¼venli deÄŸildir  \n",
    "\n",
    "Bu aÅŸamanÄ±n sonunda bir base model veya foundation model elde ediyorsun.    \n",
    "Bu yÃ¼zden bir sonraki aÅŸamaya geÃ§ilir.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 2) Finetuning â€” Modeli iÅŸe yarar hale getirme\n",
    "\n",
    "Pretrainingâ€™den Ã§Ä±kan model talimat anlamaz.  \n",
    "Finetuning aÅŸamasÄ±, modele **gÃ¶rev Ã¶ÄŸrettiÄŸimiz** aÅŸamadÄ±r.\n",
    "\n",
    "### Bu aÅŸamada modele ÅŸu tÃ¼r Ã¶rnekler verilir:\n",
    "- â€œSoru sorulursa cevap verâ€\n",
    "- â€œBu paragrafÄ± Ã¶zetleâ€\n",
    "- â€œBu cÃ¼mleyi Ã§evirâ€\n",
    "- â€œBu komutu yerine getirâ€\n",
    "\n",
    "Bu aÅŸamada model etiketli veri gÃ¶rÃ¼r:   \n",
    "â€œBu soruya ÅŸu cevap verilir.â€\n",
    "\n",
    "TÄ±pkÄ± bir memura gÃ¶rev eÄŸitimi vermek gibi:\n",
    "\n",
    "> **â€œSana biri ÅŸÃ¶yle sÃ¶ylerse, sen ÅŸÃ¶yle cevap ver.â€**\n",
    "\n",
    "### âœ… 1) Encoder Modellerde Finetuning (BERT gibi)\n",
    "\n",
    "**Nedir?**      \n",
    "ğŸ“Œ Metni anlamak ve sÄ±nÄ±flandÄ±rmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.     \n",
    "\n",
    "**Ne yapar?**       \n",
    "ğŸ“Œ CÃ¼mleyi anlar ve bir etiket Ã¼retir.      \n",
    "(Ã–rn: pozitif/negatif, spam/deÄŸil, kiÅŸi/yer/organizasyon vs.)       \n",
    "\n",
    "**NasÄ±l Ã§alÄ±ÅŸÄ±r?**      \n",
    "ğŸ“Œ Model cÃ¼mleden bir embedding Ã§Ä±karÄ±r â†’       \n",
    "ğŸ“Œ Bu embedding kÃ¼Ã§Ã¼k bir sÄ±nÄ±flandÄ±rma katmanÄ±na verilir â†’     \n",
    "ğŸ“Œ SonuÃ§: Tek bir sÄ±nÄ±f ya da token token sÄ±nÄ±f Ã§Ä±kar.      \n",
    "\n",
    "**Ã–zet:**       \n",
    "Encoder finetuning = â€œMetni anla â†’ sÄ±nÄ±fa dÃ¶nÃ¼ÅŸtÃ¼r.â€        \n",
    "\n",
    "### âœ… 2) Decoder Modellerde Finetuning (GPT/Llama gibi)\n",
    "\n",
    "**Nedir?**      \n",
    "ğŸ“Œ Metin Ã¼retmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.       \n",
    "\n",
    "**Ne yapar?**       \n",
    "ğŸ“Œ Soruya, komuta veya girdiye metin Ã¼retir.        \n",
    "(Ã–rn: soruâ€“cevap, Ã§eviri, Ã¶zet, sohbet, Instruction tuning (komut + cevap))     \n",
    "\n",
    "**NasÄ±l Ã§alÄ±ÅŸÄ±r?**      \n",
    "ğŸ“Œ Modele â€œgirdi â†’ doÄŸru yanÄ±tâ€ Ã¶rnekleri gÃ¶sterilir â†’      \n",
    "ğŸ“Œ Model bu yanÄ±tlarÄ± Ã¼retmeyi Ã¶ÄŸrenir.     \n",
    "\n",
    "**Ã–zet:**       \n",
    "Decoder finetuning = â€œGirdi ver â†’ doÄŸru metni Ã¼ret.â€        \n",
    "\n",
    "\n",
    "### âœ” Parameter Efficient Finetuning (PEFT)\n",
    "\n",
    "BÃ¼yÃ¼k modelleri tamamen gÃ¼ncellemek pahalÄ±dÄ±r.      \n",
    "Bu yÃ¼zden LoRA (Low-Rank Adaptation) gibi yÃ¶ntemler geliÅŸtirilmiÅŸtir.       \n",
    "\n",
    "**LoRA (Low-Rank Adaptation), bÃ¼yÃ¼k dil modellerini yeniden eÄŸitirken tÃ¼m aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellemek yerine, sadece Ã§ok kÃ¼Ã§Ã¼k â€œek matrislerâ€ ekleyerek modeli finetune etmeyi saÄŸlayan bir tekniktir. Yani modelin kendisine dokunmaz, yanÄ±na minik bir eklenti koyar.**\n",
    "\n",
    "**Ã–rnek:**\n",
    "- Tam katman: 1,048,576 parametre\n",
    "- LoRA (rank 16): 32,768 parametre  \n",
    "\n",
    "Bu sayede:      \n",
    "- GPU ihtiyacÄ± azalÄ±r\n",
    "- Kurumlar kendi verilerine uygun model yaratabilir\n",
    "- BÃ¼yÃ¼k modelleri tamamen eÄŸitmek Ã§ok pahalÄ±dÄ±r.  \n",
    "- LoRA ile katmanlarÄ±n kÃ¼Ã§Ã¼k ek parÃ§alarÄ± eÄŸitilir ve sÃ¼reÃ§ Ã§ok daha ucuz hale gelir.\n",
    "\n",
    "---\n",
    "\n",
    "# 3) Alignment â€” Modeli insan gibi ve gÃ¼venli hale getirme\n",
    "\n",
    "Finetuning bile yeterli deÄŸildir.  \n",
    "Model hÃ¢lÃ¢:\n",
    "- kaba olabilir  \n",
    "- yanlÄ±ÅŸ yÃ¶nlendirebilir  \n",
    "- tehlikeli Ã¶neriler verebilir  \n",
    "\n",
    "Bu yÃ¼zden **alignment** yapÄ±lÄ±r.\n",
    "\n",
    "Alignmentâ€™Ä±n amacÄ±:\n",
    "\n",
    "> **Modelin gÃ¼venli, yardÄ±msever, saygÄ±lÄ±, kontrollÃ¼ biÃ§imde konuÅŸmasÄ±nÄ± saÄŸlamak.**\n",
    "\n",
    "### âœ” En Ã¶nemli yÃ¶ntem: RLHF (Human Feedbackâ€™ten Ã–ÄŸrenme)\n",
    "\n",
    "SÃ¼reÃ§ basitÃ§e ÅŸÃ¶yledir:\n",
    "\n",
    "1. Modele bir soru sorulur ve iki cevap Ã¼rettirilir.  \n",
    "2. Ä°nsanlar hangi cevabÄ±n daha iyi olduÄŸunu seÃ§er.  \n",
    "3. Bu seÃ§imlerle bir **Ã¶dÃ¼l modeli** eÄŸitilir.  \n",
    "4. Dil modeli, yÃ¼ksek Ã¶dÃ¼l alan davranÄ±ÅŸlarÄ± Ã¶ÄŸrenir.\n",
    "\n",
    "SonuÃ§:\n",
    "- Kibar  \n",
    "- KullanÄ±cÄ±yÄ± daha iyi yÃ¶nlendiren  \n",
    "- ZararlÄ± iÃ§erikten kaÃ§Ä±nan  \n",
    "- Ä°nsan deÄŸerleriyle uyumlu bir model  \n",
    "\n",
    "### âœ” DPO\n",
    "RLHFâ€™nin daha basit, Ã¶dÃ¼l modeli gerektirmeyen bir alternatifidir.\n",
    "\n",
    "---\n",
    "\n",
    "# 4) Reasoning â€” Modelin adÄ±m adÄ±m dÃ¼ÅŸÃ¼nmeyi Ã¶ÄŸrenmesi\n",
    "\n",
    "Model artÄ±k:\n",
    "- dili biliyor (pretraining)\n",
    "- gÃ¶rev biliyor (finetuning)\n",
    "- gÃ¼venli konuÅŸuyor (alignment)\n",
    "\n",
    "Ama bir eksik var:\n",
    "\n",
    "> **Model genelde akÄ±l yÃ¼rÃ¼tmeyi doÄŸal olarak bilmez.**\n",
    "\n",
    "Ã–rnek:  \n",
    "â€œAliâ€™de 4 elma, Ahmetâ€™te 2 elma var. Ali yarÄ±sÄ±nÄ± verirseâ€¦â€  \n",
    "Bu tÃ¼r problemlerde model **adÄ±m adÄ±m dÃ¼ÅŸÃ¼nme** yeteneÄŸi ister.\n",
    "\n",
    "### âœ” Ã‡Ã¶zÃ¼m 1: Chain-of-Thought\n",
    "Modele:\n",
    "> **â€œLetâ€™s think step by step.â€**  \n",
    "demek, onun dÃ¼ÅŸÃ¼nce adÄ±mlarÄ± Ã¼retmesini saÄŸlar.\n",
    "\n",
    "### âœ” Ã‡Ã¶zÃ¼m 2: RL tabanlÄ± reasoning\n",
    "DeepSeek-R1 gibi modellerde:\n",
    "- doÄŸru akÄ±l yÃ¼rÃ¼tme â†’ Ã¶dÃ¼l  \n",
    "- yanlÄ±ÅŸ akÄ±l yÃ¼rÃ¼tme â†’ ceza  \n",
    "verilir ve model mantÄ±klÄ± Ã§Ã¶zÃ¼m yollarÄ±nÄ± Ã¶ÄŸrenir.\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ TÃ¼m Dersin En Basit Ã–zeti (Tek Paragraf)\n",
    "\n",
    "1. **Pretraining:** Model devasa metinlerle dili Ã¶ÄŸrenir.  \n",
    "2. **Finetuning:** â€œBu gÃ¶revi bÃ¶yle yapâ€ diyerek gÃ¶rev becerisi kazandÄ±rÄ±lÄ±r.  \n",
    "3. **Alignment:** Model gÃ¼venli, kibar ve insan-misal davranÄ±ÅŸa hizalanÄ±r.  \n",
    "4. **Reasoning:** Model adÄ±m adÄ±m dÃ¼ÅŸÃ¼nmeyi Ã¶ÄŸrenerek karmaÅŸÄ±k problemleri Ã§Ã¶zebilir hale gelir.\n",
    "\n",
    "Bu dÃ¶rt aÅŸamanÄ±n birleÅŸimiyle **ChatGPT, Claude, Gemini, Llama gibi modern dil modelleri** ortaya Ã§Ä±kar.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
