{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f86d8ef",
   "metadata": {},
   "source": [
    "# ğŸ§  1. Derin Ã–ÄŸrenmeye GiriÅŸ\n",
    "\n",
    "Derin Ã¶ÄŸrenme (Deep Learning), **makine Ã¶ÄŸrenmesinin bir alt dalÄ±dÄ±r**, ama Ã§ok katmanlÄ± sinir aÄŸlarÄ± sayesinde klasik yÃ¶ntemlerden Ã§ok daha gÃ¼Ã§lÃ¼dÃ¼r.  \n",
    "Temel fark ÅŸu:\n",
    "\n",
    "- **Klasik Makine Ã–ÄŸrenmesi:**  \n",
    "  YÃ¼ksek boyutlu verilerle (Ã¶rneÄŸin gÃ¶rÃ¼ntÃ¼ veya ses) iyi baÅŸ edemezler.  \n",
    "  Ã–zellik Ã§Ä±karÄ±mÄ± (feature extraction) zor ve genellikle insan mÃ¼dahalesine baÄŸlÄ±dÄ±r.  \n",
    "\n",
    "- **Derin Ã–ÄŸrenme:**  \n",
    "  Ã–zellikleri otomatik olarak Ã¶ÄŸrenir.  \n",
    "  Her katman, girdiyi dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p bir â€œtemsilâ€ oluÅŸturur ve her katman, bir Ã¶nceki katmanÄ±n Ã§Ä±ktÄ±sÄ±nÄ± girdi olarak alÄ±r:  \n",
    "  Ã¶rneÄŸin, ilk katman kenarlarÄ±, ikinci katman ÅŸekilleri, son katman nesneleri tanÄ±r.\n",
    "\n",
    "> ğŸ” Yani derin Ã¶ÄŸrenme, â€œham veriden anlam Ã§Ä±karma iÅŸiniâ€ insanÄ±n elinden alÄ±p modele devreder.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ba51c",
   "metadata": {},
   "source": [
    "# ğŸš€ 2. Derin Ã–ÄŸrenmenin YÃ¼kseliÅŸ Sebepleri\n",
    "\n",
    "Derin Ã¶ÄŸrenmenin popÃ¼lerleÅŸmesi Ã¼Ã§ ana faktÃ¶re dayanÄ±r:\n",
    "\n",
    "### ğŸ§© a) BÃ¼yÃ¼k Veri (Big Data)\n",
    "\n",
    "ArtÄ±k her ÅŸeyden veri toplanabiliyor: telefonlar, sensÃ¶rler, internet.  \n",
    "Bu sayede derin aÄŸlarÄ±n Ã¶ÄŸrenmesi iÃ§in milyonlarca Ã¶rnek mevcut.  \n",
    "â†’ Daha fazla veri = Daha iyi genelleme.\n",
    "\n",
    "### âš™ï¸ b) DonanÄ±m GeliÅŸmeleri\n",
    "\n",
    "- GPUâ€™lar (Grafik Ä°ÅŸlemciler) Ã§ok sayÄ±da iÅŸlemi **paralel** yapabilir.  \n",
    "- Derin Ã¶ÄŸrenme, milyonlarca parametreyle Ã§alÄ±ÅŸÄ±r; GPUâ€™lar bu yÃ¼kÃ¼ hafifletir.  \n",
    "- CUDA, Tensor Core gibi teknolojiler eÄŸitimi hÄ±zlandÄ±rdÄ±.\n",
    "\n",
    "### ğŸ§  c) YazÄ±lÄ±m GeliÅŸmeleri\n",
    "\n",
    "- TensorFlow, PyTorch, Keras gibi kÃ¼tÃ¼phanelerle model kurmak artÄ±k birkaÃ§ satÄ±r kodla mÃ¼mkÃ¼n.  \n",
    "- Yeni optimizasyon teknikleri ve modeller (CNN, RNN, Transformer) sÃ¼rekli geliÅŸiyor.\n",
    "\n",
    "> ğŸ”¸ SonuÃ§: 2012 sonrasÄ± derin Ã¶ÄŸrenme, gÃ¶rme (vision), ses (speech), dil (NLP) gibi alanlarda devrim yarattÄ±.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313ac6a",
   "metadata": {},
   "source": [
    "# ğŸ§© 3. Model EÄŸitiminin Temel AdÄ±mlarÄ±\n",
    "\n",
    "Bir sinir aÄŸÄ±nÄ± eÄŸitirken ÅŸu adÄ±mlar izlenir:\n",
    "\n",
    "**1ï¸âƒ£ Veriyi bÃ¶l:**  \n",
    "   EÄŸitim (%70), doÄŸrulama (%15), test (%15).  \n",
    "   BÃ¶ylece modelin genelleme yeteneÄŸi Ã¶lÃ§Ã¼lÃ¼r.\n",
    "\n",
    "   | KÄ±sÄ±m                      | AmaÃ§                                                      | Oran |\n",
    "   | -------------------------- | --------------------------------------------------------- | ---- |\n",
    "   | **Train (EÄŸitim)**         | Modelin Ã¶ÄŸrenmesi (aÄŸÄ±rlÄ±klar gÃ¼ncellenir)                | %70  |\n",
    "   | **Validation (DoÄŸrulama)** | Modelin performansÄ±nÄ± izlemek, overfittingâ€™i tespit etmek | %15  |\n",
    "   | **Test**                   | EÄŸitim bitince, nihai performansÄ± Ã¶lÃ§mek                  | %15  |     \n",
    "\n",
    "\n",
    "**2ï¸âƒ£ Shuffle (karÄ±ÅŸtÄ±r):**  \n",
    "   Veri sÄ±ralÄ±ysa (Ã¶rneÄŸin ilk 100 Ã¶rnek â€œkediâ€, sonraki 100 â€œkÃ¶pekâ€), model bu sÄ±ralamayÄ± Ã¶ÄŸrenebilir.     \n",
    "   Bu durumda model â€œverinin sÄ±rasÄ±â€ Ã¼zerinden tahmin yapar, yani hatalÄ± Ã¶ÄŸrenir.\n",
    "\n",
    "   Bu yÃ¼zden her epoch Ã¶ncesinde veriler karÄ±ÅŸtÄ±rÄ±lÄ±r (shuffle).     \n",
    "   Bu, gradyan gÃ¼ncellemelerini daha â€œrasgeleâ€ hale getirir ve modelin daha saÄŸlam Ã¶ÄŸrenmesini saÄŸlar.   \n",
    "\n",
    "   > ğŸ’¡ PyTorchâ€™ta DataLoader(..., shuffle=True) tam olarak bu iÅŸi yapar.\n",
    "\n",
    "**3ï¸âƒ£ Preprocessing (Ã¶n iÅŸleme):**  \n",
    "   Ham veri genellikle modelin doÄŸrudan anlayamayacaÄŸÄ± formdadÄ±r.    \n",
    "   Ã–n iÅŸleme aÅŸamasÄ±, veriyi standart hale getirir.\n",
    "\n",
    "   - **ğŸ§® SayÄ±sal Veriler:**\n",
    "\n",
    "   Normalizasyon / Standardizasyon:\n",
    "\n",
    "   - **ğŸ–¼ï¸ GÃ¶rsel Veriler:**\n",
    "\n",
    "   Piksel deÄŸerlerini 0â€“1 aralÄ±ÄŸÄ±na Ã§evir: x = x / 255.0    \n",
    "   Gerekirse yeniden boyutlandÄ±r (resize(224,224)).\n",
    "\n",
    "   - **ğŸ”¤ Kategorik Veriler:**\n",
    "\n",
    "   One-hot encoding: sÄ±nÄ±flarÄ± vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. \n",
    "   Ã–rn: renk = {kÄ±rmÄ±zÄ±, mavi, yeÅŸil}  \n",
    "   â†’ [1,0,0], [0,1,0], [0,0,1]\n",
    "\n",
    "   - **ğŸ’¬ Metin Verileri:**\n",
    "\n",
    "   Tokenization (kelimelere veya alt parÃ§alara bÃ¶lme)    \n",
    "   Embedding (vektÃ¶r temsiline dÃ¶nÃ¼ÅŸtÃ¼rme)\n",
    "\n",
    "   > ğŸ¯ **AmaÃ§:** TÃ¼m veri tÃ¼rlerini modelin doÄŸrudan iÅŸleyebileceÄŸi biÃ§imde **sayÄ±sal ve normalize edilmiÅŸ** hale getirmek.\n",
    "\n",
    "\n",
    "**4ï¸âƒ£ Hiperparametreleri belirle:**  \n",
    "   Ã–ÄŸrenme oranÄ±, batch size, epoch sayÄ±sÄ± gibi.\n",
    "\n",
    "   | Hiperparametre        | AÃ§Ä±klama                                   |\n",
    "   | --------------------- | ------------------------------------------ |\n",
    "   | **Learning Rate (Î·)** | AÄŸÄ±rlÄ±klarÄ±n ne kadar hÄ±zla gÃ¼ncelleneceÄŸi |\n",
    "   | **Batch Size**        | Her adÄ±mda kaÃ§ Ã¶rnekle gÃ¼ncelleneceÄŸi      |\n",
    "   | **Epoch**             | Verinin aÄŸdan kaÃ§ kez geÃ§eceÄŸi             |\n",
    "   | **Optimizer**         | SGD, Adam vb.                              |\n",
    "   | **Dropout Rate**      | NÃ¶ronlarÄ±n kaÃ§Ä± rastgele kapatÄ±lacak       |\n",
    "\n",
    "\n",
    "**5ï¸âƒ£ Forward Pass:**  \n",
    "   Bu, modelin â€œtahmin yaptÄ±ÄŸÄ±â€ adÄ±mdÄ±r.  \n",
    "   Burada:  \n",
    "   - ğ‘¤: AÄŸÄ±rlÄ±klar\n",
    "\n",
    "   - ğ‘: Bias\n",
    "\n",
    "   - ğ‘“: Aktivasyon fonksiyonu (Ã¶rneÄŸin ReLU)\n",
    "\n",
    "   Son katmanda Ã§Ä±ktÄ± (Ã¶rneÄŸin â€œkedi olasÄ±lÄ±ÄŸÄ± = 0.93â€) elde edilir.    \n",
    "   Bu tahmin, loss hesaplamasÄ±nda kullanÄ±lacak.\n",
    "\n",
    "**6ï¸âƒ£ Loss (KayÄ±p) Hesapla:**  \n",
    "   Loss, modelin tahmini ile gerÃ§ek etiket arasÄ±ndaki farktÄ±r.   \n",
    "   Bu farkÄ± sayÄ±sal olarak Ã¶lÃ§eriz.    \n",
    "   > ğŸ¯ **AmaÃ§:** Loss ne kadar kÃ¼Ã§Ã¼kse, modelin tahmini o kadar doÄŸru.\n",
    "\n",
    "\n",
    "**7ï¸âƒ£ Backward Pass:**  \n",
    "   Gradyanlar hesaplanÄ±r ve aÄŸÄ±rlÄ±klara â€œgeri yayÄ±lÄ±râ€.  \n",
    "   Burada, lossâ€™un her bir aÄŸÄ±rlÄ±k Ã¼zerindeki etkisi tÃ¼rev ile hesaplanÄ±r     \n",
    "   Bu tÃ¼rev, zincir kuralÄ± (chain rule) ile katman katman geriye doÄŸru hesaplanÄ±r.\n",
    "   O yÃ¼zden adÄ±na **backpropagation** denir:\n",
    "\n",
    "      ğŸ” Matematikte tÃ¼rev ne iÅŸe yarar?\n",
    "      AÄŸÄ±rlÄ±k deÄŸiÅŸirse loss nasÄ±l deÄŸiÅŸir â€” yani â€œhangi yÃ¶nde azaltayÄ±m?â€\n",
    "\n",
    "   Bu bilgi optimizasyona iletilir.\n",
    "\n",
    "**8ï¸âƒ£ Optimize Et:**  \n",
    "   ArtÄ±k gradyanlar elimizde.    \n",
    "   AÄŸÄ±rlÄ±klarÄ± kaybÄ± azaltacak yÃ¶nde deÄŸiÅŸtiririz:    \n",
    "   Gradient descent veya Adam gibi algoritmalarla aÄŸÄ±rlÄ±klar gÃ¼ncellenir.\n",
    "\n",
    "**9ï¸âƒ£ Test:**  \n",
    "   EÄŸitim bittikten sonra hiÃ§ gÃ¶rÃ¼lmemiÅŸ test verisi ile model deÄŸerlendirilir.     \n",
    "   Burada loss hesaplanmaz, sadece performans metrikleri bakÄ±lÄ±r:    \n",
    "   - Accuracy (doÄŸruluk)\n",
    "   - Precision / Recall / F1-score\n",
    "   - Confusion Matrix\n",
    "   - ROC Curve / AUC\n",
    "\n",
    "\n",
    "> ğŸ’¡ EÄŸitim, ileri ve geri yayÄ±lÄ±mÄ±n (forward + backward) milyonlarca kez tekrarlanmasÄ±dÄ±r.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360456f5",
   "metadata": {},
   "source": [
    "# ğŸ§¾ 4. Veri Temsilleri (Data Representations)\n",
    "\n",
    "Modelin anlamasÄ± iÃ§in veriyi **sayÄ±sal vektÃ¶rlere** dÃ¶nÃ¼ÅŸtÃ¼rmek gerekir.\n",
    "\n",
    "### ğŸ”¢ SayÄ±sal Veriler\n",
    "Zaten sayÄ± olduÄŸu iÃ§in direkt kullanÄ±labilir (Ã¶rneÄŸin sensÃ¶r deÄŸerleri).\n",
    "\n",
    "### ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼ler\n",
    "GÃ¶rÃ¼ntÃ¼, piksel matrisidir.  \n",
    "Ã–rneÄŸin 64Ã—64â€™lÃ¼k gri tonlu bir resim = 4096 Ã¶zellik.  \n",
    "Renkli ise (64Ã—64Ã—3).\n",
    "\n",
    "### ğŸ”¤ Kategorik Veriler\n",
    "Ã–rnek: renk = {kÄ±rmÄ±zÄ±, mavi, yeÅŸil}  \n",
    "â†’ *One-hot encoding*:  \n",
    "- kÄ±rmÄ±zÄ± = [1, 0, 0]  \n",
    "- mavi = [0, 1, 0]  \n",
    "- yeÅŸil = [0, 0, 1]\n",
    "\n",
    "### ğŸ’¬ Metin (Text)\n",
    "DoÄŸrudan sayÄ± deÄŸildir.  \n",
    "Kelimeler â†’ embedding vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r (Ã¶rneÄŸin Word2Vec, BERT).\n",
    "\n",
    "### ğŸµ Ses (Audio)\n",
    "Zaman serisidir.  \n",
    "Spektrogram (frekans + zaman) olarak modele verilebilir.\n",
    "\n",
    "> ğŸ” Her veri tÃ¼rÃ¼, uygun ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeden derin aÄŸlar tarafÄ±ndan iÅŸlenemez.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b1af",
   "metadata": {},
   "source": [
    "# ğŸ§® 5. Hesaplama Grafikleri (Computational Graphs)\n",
    "\n",
    "Derin Ã¶ÄŸrenmede her iÅŸlem (Ã§arpma, toplama, aktivasyon) bir **dÃ¼ÄŸÃ¼m** olarak grafik Ã¼zerinde temsil edilir.  \n",
    "Bu grafik sayesinde otomatik tÃ¼rev (autograd) hesaplanÄ±r.\n",
    "\n",
    "Ã–rnek:\n",
    "\n",
    "> x â†’ (w*x + b) â†’ ReLU â†’ Loss\n",
    "\n",
    "- Ä°leri geÃ§iÅŸte deÄŸerler hesaplanÄ±r.  \n",
    "- Geri geÃ§iÅŸte, zincir kuralÄ± (chain rule) ile her dÃ¼ÄŸÃ¼mÃ¼n gradyanÄ± bulunur.\n",
    "\n",
    "> Bu mekanizma, PyTorchâ€™ta `requires_grad=True` ile otomatik yapÄ±lÄ±r.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eea1f2",
   "metadata": {},
   "source": [
    "# ğŸ§  6. Multi-Layer Perceptron (MLP)\n",
    "\n",
    "En basit sinir aÄŸÄ± tÃ¼rÃ¼dÃ¼r.\n",
    "\n",
    "### YapÄ±sÄ±:\n",
    "- **Input Layer:** Ham veriyi alÄ±r.  \n",
    "- **Hidden Layers:** Ã–zellikleri Ã¶ÄŸrenir.  \n",
    "- **Output Layer:** Tahmini Ã¼retir.  \n",
    "- **Weights:** BaÄŸlantÄ±larÄ±n gÃ¼cÃ¼.  \n",
    "- **Bias:** Sabit kaydÄ±rma deÄŸeri.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794184a0",
   "metadata": {},
   "source": [
    "# âš™ï¸ 7. Aktivasyon FonksiyonlarÄ±\n",
    "\n",
    "Aktivasyon fonksiyonu, bir nÃ¶ronun Ã¼rettiÄŸi deÄŸeri veya denklemi alÄ±r ve bunu doÄŸrusal olmayan (non-linear) bir biÃ§imde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:     \n",
    "Bunu yapmamÄ±zÄ±n sebebi modelin sadece doÄŸrusal deÄŸil doÄŸrusal olmayan durumlarda da baÅŸarÄ± gÃ¶stermesini saÄŸlamak.   \n",
    "Ã‡Ã¼nkÃ¼ gerÃ§ek hayatta herÅŸey doÄŸrusal ilerlemez.\n",
    "\n",
    "### ğŸ§© SÄ±k KullanÄ±lanlar\n",
    "\n",
    "| Fonksiyon |Ã–zellik |\n",
    "|------------|----------|\n",
    "| **Sigmoid** |0â€“1 arasÄ± Ã§Ä±ktÄ±, vanishing gradient riski |\n",
    "| **Tanh** |-1â€“1 arasÄ± Ã§Ä±ktÄ±, merkezli |\n",
    "| **ReLU** |hÄ±zlÄ±, basit, vanishing gradient azaltÄ±r |\n",
    "| **Leaky ReLU** |ReLUâ€™nun kÃ¼Ã§Ã¼k varyantÄ± |\n",
    "| **Softmax** | Ã§ok sÄ±nÄ±flÄ± olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± Ã¼retir |\n",
    "\n",
    "\n",
    "### ğŸ§© KÄ±saca\n",
    "\n",
    "- Aktivasyon fonksiyonlarÄ±, sinir aÄŸlarÄ±na â€œbeyinâ€ kazandÄ±rÄ±r.\n",
    "- Onlar olmadan aÄŸ sadece doÄŸrusal olur, karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenemez.\n",
    "- ReLU (ve tÃ¼revleri) gÃ¼nÃ¼mÃ¼zde gizli katmanlarda en yaygÄ±n,\n",
    "- Sigmoid / Softmax ise genellikle Ã§Ä±ktÄ± katmanÄ±nda kullanÄ±lÄ±r.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486d5d0",
   "metadata": {},
   "source": [
    "# ğŸ“‰ 8. KayÄ±p FonksiyonlarÄ± (Loss Functions)\n",
    "\n",
    "Modelin â€œne kadar hatalÄ± olduÄŸunuâ€ Ã¶lÃ§er.  \n",
    "EÄŸitimde minimize edilmesi gerekir.\n",
    "\n",
    "### Ã–rnekler:\n",
    "- **Mean Squared Error (MSE):** regresyon iÃ§in  \n",
    "- **Binary Cross Entropy (BCE):** iki sÄ±nÄ±f iÃ§in  \n",
    "- **Cross Entropy:** birden fazla sÄ±nÄ±f iÃ§in  \n",
    "\n",
    "Cross Entropyâ€™nin mantÄ±ÄŸÄ±:  \n",
    "Modelin tahmin ettiÄŸi olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± ile gerÃ§ek daÄŸÄ±lÄ±m (Ã¶rneÄŸin [0,0,1]) arasÄ±ndaki farkÄ± Ã¶lÃ§er.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2390d83",
   "metadata": {},
   "source": [
    "# ğŸ§­ 9. Optimizasyon ve Geri YayÄ±lÄ±m\n",
    "\n",
    "### ğŸŸ¢ Gradient Descent\n",
    "Gradient Descent ile modelin Ã¼rettiÄŸi hatayÄ± (Loss) mÃ¼mkÃ¼n olduÄŸunca azaltmak isteriz.     \n",
    "Bu azaltmayÄ± backpropagation ile hesaplanan gradyanlar ile yaparÄ±z.     \n",
    "Bulunan gradyanlar ile aÄŸÄ±rlÄ±klar gÃ¼ncellenir \"gradient descent\".\n",
    "\n",
    "\n",
    "### ğŸ”„ Backpropagation\n",
    "KayÄ±ptan baÅŸlayarak, zincir kuralÄ±yla gradyanlar geriye doÄŸru hesaplanÄ±r.  \n",
    "Bu sayede her katmandaki aÄŸÄ±rlÄ±k gÃ¼ncellenir.\n",
    "\n",
    "### âš ï¸ Vanishing Gradient Problemi\n",
    "Derin aÄŸlarda, erken katmanlara ulaÅŸtÄ±ÄŸÄ±nda gradyanlar neredeyse sÄ±fÄ±r olur â†’ Ã¶ÄŸrenme durur.\n",
    "\n",
    "**Ã‡Ã¶zÃ¼m YÃ¶ntemleri:**\n",
    "- Aktivasyon FonksiyonlarÄ±  \n",
    "- Skip Connection   \n",
    "- Residual Network  \n",
    "- Gradient Clipping\n",
    "\n",
    "**ğŸ”„ Mini AkÄ±ÅŸ Ã–zeti:**\n",
    "- 1ï¸âƒ£ Forward pass   â†’ Tahmin yap\n",
    "- 2ï¸âƒ£ Loss hesapla   â†’ Hata Ã¶lÃ§\n",
    "- 3ï¸âƒ£ Backpropagation â†’ Hangi aÄŸÄ±rlÄ±k ne kadar hatalÄ±?\n",
    "- 4ï¸âƒ£ Gradient Descent â†’ HatalÄ± aÄŸÄ±rlÄ±klarÄ± dÃ¼zelt\n",
    "- 5ï¸âƒ£ Tekrar et ğŸ”\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1f858",
   "metadata": {},
   "source": [
    "# âš™ï¸ 10. Optimizasyon AlgoritmalarÄ±\n",
    "\n",
    "### ğŸš¶â€â™‚ï¸ SGD (Stochastic Gradient Descent)\n",
    "Her iterasyonda kÃ¼Ã§Ã¼k veri parÃ§alarÄ±yla (mini-batch) gÃ¼ncelleme yapar.  \n",
    "Daha gÃ¼rÃ¼ltÃ¼lÃ¼ ama daha hÄ±zlÄ±dÄ±r.\n",
    "\n",
    "### ğŸ¤– Adam Optimizer\n",
    "SGDâ€™nin geliÅŸmiÅŸ hÃ¢lidir.\n",
    "- Momentum + adaptif Ã¶ÄŸrenme oranÄ± iÃ§erir.  \n",
    "- Parametreler: Î²â‚=0.9, Î²â‚‚=0.999, Îµâ‰ˆ1e-8  \n",
    "- Denklem: Ortalama gradyan (m) ve varyans (v) tutulur; aÄŸÄ±rlÄ±k bu iki bilgiyle dengeli gÃ¼ncellenir.\n",
    "\n",
    "### ğŸ“‰ LR Scheduler\n",
    "Ã–ÄŸrenme oranÄ±nÄ± zamanla azaltÄ±r.  \n",
    "Modelin yerel minimuma sÄ±kÄ±ÅŸmadan daha iyi minimuma inmesini saÄŸlar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13295247",
   "metadata": {},
   "source": [
    "# ğŸ§© 11. AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) ve DÃ¼zenleme (Regularization)\n",
    "\n",
    "**Overfitting:**  \n",
    "Model, eÄŸitim verisini ezberler; yeni veride kÃ¶tÃ¼ performans gÃ¶sterir.\n",
    "\n",
    "### ğŸ”§ Ã‡Ã¶zÃ¼m Teknikleri:\n",
    "- **Dropout:** Rastgele bazÄ± nÃ¶ronlarÄ± pasifleÅŸtirerek baÄŸÄ±mlÄ±lÄ±ÄŸÄ± azaltÄ±r.  \n",
    "- **Early Stopping:** Validation Loss artmaya baÅŸladÄ±ÄŸÄ±nda eÄŸitimi durdurur.  \n",
    "- **Regularization (L1/L2):** AÄŸÄ±rlÄ±klarÄ± sÄ±nÄ±rlayarak daha basit modelleri teÅŸvik eder.\n",
    "\n",
    "> ğŸ” Ã–zetle, dÃ¼zenleme yÃ¶ntemleri â€œezberleyen deÄŸil, genelleyenâ€ modeller Ã¼retir.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bc474",
   "metadata": {},
   "source": [
    "# âœ… 12. KapanÄ±ÅŸ\n",
    "\n",
    "*HazÄ±rlayan: Ayberk â€” Mekatronik MÃ¼hendisi*  \n",
    "*Odak AlanlarÄ±: Yapay Zeka â€¢ Derin Ã–ÄŸrenme â€¢ LLM â€¢ Makine Ã–ÄŸrenmesi â€¢ Veri Bilimi*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
